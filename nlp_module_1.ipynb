{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86b8c806",
   "metadata": {},
   "source": [
    "**Question 1:** What is Computational Linguistics and how does it relate to NLP? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45afff33",
   "metadata": {},
   "source": [
    "Ans- Computational linguistics is a theoretical field that uses computational methods to study language, while Natural Language Processing (NLP) is its applied counterpart, focusing on developing practical applications that enable computers to process and understand human language. In short, computational linguistics explores the theory and models of language, whereas NLP uses those theories and models to build things like chatbots, speech recognition, and machine translation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b4c58",
   "metadata": {},
   "source": [
    "**Question 2:** Briefly describe the historical evolution of Natural Language Processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186730ce",
   "metadata": {},
   "source": [
    "Ans- NLP has evolved from early rule-based systems in the 1950s to statistical methods in the 1980s-2000s, and has since been revolutionized by neural networks and deep learning, especially with the rise of large language models in the 2010s and 2020s. Key advancements include the shift from hand-written rules to statistical models that learn from data, the development of recurrent neural networks (RNNs), and the emergence of transformers and other deep learning models that can handle vast amounts of text. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e4cc99",
   "metadata": {},
   "source": [
    "**Question 3:** List and explain three major use cases of NLP in today’s tech industry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da9a0f8",
   "metadata": {},
   "source": [
    "Ans- Three major use cases of NLP in today's tech industry are customer service automation through chatbots, search and information retrieval like in search engines, and business intelligence and analytics such as sentiment analysis and market trend prediction. NLP enables businesses to automate interactions, understand user intent, and extract actionable insights from vast amounts of text data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d6765",
   "metadata": {},
   "source": [
    "**Question 4:** What is text normalization and why is it essential in text processing tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf897a",
   "metadata": {},
   "source": [
    "Ans- Text normalization is the process of converting raw text into a standard, consistent format, which is essential in text processing for reducing complexity and improving model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27166104",
   "metadata": {},
   "source": [
    "**Question 5:** Compare and contrast stemming and lemmatization with suitable \n",
    "examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bbc392",
   "metadata": {},
   "source": [
    "Ans- Stemming and lemmatization are both techniques used in Natural Language Processing (NLP) to reduce words to their base or root form, but they differ in their approach and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b398c676",
   "metadata": {},
   "source": [
    "**Question 6:** Write a Python program that uses regular expressions (regex) to extract all \n",
    "email addresses from the following block of text: \n",
    "“Hello team, please contact us at support@xyz.com for technical issues, or reach out to \n",
    "our HR at hr@xyz.com. You can also connect with John at john.doe@xyz.org and jenny \n",
    "via jenny_clarke126@mail.co.us. For partnership inquiries, email partners@xyz.biz.” \n",
    "(Include your Python code and output in the code box below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf7f196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['support@xyz.com', 'hr@xyz.com', 'john.doe@xyz.org', 'jenny_clarke126@mail.co.us', 'partners@xyz.biz']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"\n",
    "    Hello team, please contact us at support@xyz.com for technical issues, or reach out to \n",
    "    our HR at hr@xyz.com. You can also connect with John at john.doe@xyz.org and jenny \n",
    "    via jenny_clarke126@mail.co.us. For partnership inquiries, email partners@xyz.biz.\n",
    "\"\"\"\n",
    "\n",
    "pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "\n",
    "emails = re.findall(pattern, text)\n",
    "\n",
    "print(emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad6d365",
   "metadata": {},
   "source": [
    "**Question 7:** Given the sample paragraph below, perform string tokenization and \n",
    "frequency distribution using Python and NLTK: \n",
    "“Natural Language Processing (NLP) is a fascinating field that combines linguistics, \n",
    "computer science, and artificial intelligence. It enables machines to understand, \n",
    "interpret, and generate human language. Applications of NLP include chatbots, \n",
    "sentiment analysis, and machine translation. As technology advances, the role of NLP \n",
    "in modern solutions is becoming increasingly critical.” \n",
    "(Include your Python code and output in the code box below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38ff9c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'fascinating', 'field', 'that', 'combines', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', '.', 'It', 'enables', 'machines', 'to', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', '.', 'Applications', 'of', 'NLP', 'include', 'chatbots', ',', 'sentiment', 'analysis', ',', 'and', 'machine', 'translation', '.', 'As', 'technology', 'advances', ',', 'the', 'role', 'of', 'NLP', 'in', 'modern', 'solutions', 'is', 'becoming', 'increasingly', 'critical', '.']\n",
      "\n",
      "Frequency Distribution:\n",
      "Natural: 1\n",
      "Language: 1\n",
      "Processing: 1\n",
      "(: 1\n",
      "NLP: 3\n",
      "): 1\n",
      "is: 2\n",
      "a: 1\n",
      "fascinating: 1\n",
      "field: 1\n",
      "that: 1\n",
      "combines: 1\n",
      "linguistics: 1\n",
      ",: 7\n",
      "computer: 1\n",
      "science: 1\n",
      "and: 3\n",
      "artificial: 1\n",
      "intelligence: 1\n",
      ".: 4\n",
      "It: 1\n",
      "enables: 1\n",
      "machines: 1\n",
      "to: 1\n",
      "understand: 1\n",
      "interpret: 1\n",
      "generate: 1\n",
      "human: 1\n",
      "language: 1\n",
      "Applications: 1\n",
      "of: 2\n",
      "include: 1\n",
      "chatbots: 1\n",
      "sentiment: 1\n",
      "analysis: 1\n",
      "machine: 1\n",
      "translation: 1\n",
      "As: 1\n",
      "technology: 1\n",
      "advances: 1\n",
      "the: 1\n",
      "role: 1\n",
      "in: 1\n",
      "modern: 1\n",
      "solutions: 1\n",
      "becoming: 1\n",
      "increasingly: 1\n",
      "critical: 1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "text = \"\"\"Natural Language Processing (NLP) is a fascinating field that combines linguistics,\n",
    "computer science, and artificial intelligence. It enables machines to understand,\n",
    "interpret, and generate human language. Applications of NLP include chatbots,\n",
    "sentiment analysis, and machine translation. As technology advances, the role of NLP\n",
    "in modern solutions is becoming increasingly critical.\"\"\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\")\n",
    "print(tokens)\n",
    "\n",
    "# Frequency Distribution\n",
    "freq_dist = FreqDist(tokens)\n",
    "print(\"\\nFrequency Distribution:\")\n",
    "for word, freq in freq_dist.items():\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93923d37",
   "metadata": {},
   "source": [
    "**Question 8:** Create a custom annotator using spaCy or NLTK that identifies and labels \n",
    "proper nouns in a given text. \n",
    "(Include your Python code and output in the code box below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98da6395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': 'Apple', 'tag': 'NNP', 'index': 0, 'label': 'PROPER_NOUN'}\n",
      "{'token': 'John', 'tag': 'NNP', 'index': 2, 'label': 'PROPER_NOUN'}\n",
      "{'token': 'New', 'tag': 'NNP', 'index': 6, 'label': 'PROPER_NOUN'}\n",
      "{'token': 'York', 'tag': 'NNP', 'index': 7, 'label': 'PROPER_NOUN'}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def annotate_proper_nouns(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "\n",
    "    annotations = []\n",
    "    for i, (word, tag) in enumerate(tagged):\n",
    "        if tag in (\"NNP\", \"NNPS\"):\n",
    "            annotations.append({\n",
    "                \"token\": word,\n",
    "                \"tag\": tag,\n",
    "                \"index\": i,\n",
    "                \"label\": \"PROPER_NOUN\"\n",
    "            })\n",
    "    return annotations\n",
    "\n",
    "text = \"Apple hired John to work in New York.\"\n",
    "anns = annotate_proper_nouns(text)\n",
    "\n",
    "for ann in anns:\n",
    "    print(ann)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd980b37",
   "metadata": {},
   "source": [
    "**Question 9:** Using Genism, demonstrate how to train a simple Word2Vec model on the \n",
    "following dataset consisting of example sentences: \n",
    "dataset = [ \n",
    "\"Natural language processing enables computers to understand human language\", \n",
    "\"Word embeddings are a type of word representation that allows words with similar \n",
    "meaning to have similar representation\", \n",
    "\"Word2Vec is a popular word embedding technique used in many NLP applications\", \n",
    "\"Text preprocessing is a critical step before training word embeddings\", \n",
    "\"Tokenization and normalization help clean raw text for modeling\" \n",
    "] \n",
    "Write code that tokenizes the dataset, preprocesses it, and trains a Word2Vec model using \n",
    "Gensim. \n",
    "(Include your Python code and output in the code box below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ebdefe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized & preprocessed sentences:\n",
      "['natural', 'language', 'processing', 'enables', 'computers', 'to', 'understand', 'human', 'language']\n",
      "['word', 'embeddings', 'are', 'type', 'of', 'word', 'representation', 'that', 'allows', 'words', 'with', 'similar', 'meaning', 'to', 'have', 'similar', 'representation']\n",
      "['word', 'vec', 'is', 'popular', 'word', 'embedding', 'technique', 'used', 'in', 'many', 'nlp', 'applications']\n",
      "['text', 'preprocessing', 'is', 'critical', 'step', 'before', 'training', 'word', 'embeddings']\n",
      "['tokenization', 'and', 'normalization', 'help', 'clean', 'raw', 'text', 'for', 'modeling']\n",
      "\n",
      "Model vocabulary:\n",
      "['word', 'text', 'is', 'similar', 'representation', 'embeddings', 'to', 'language', 'modeling', 'for', 'raw', 'clean', 'help', 'normalization', 'and', 'tokenization', 'training', 'before', 'step', 'critical', 'preprocessing', 'applications', 'nlp', 'many', 'in', 'used', 'technique', 'embedding', 'popular', 'vec', 'have', 'meaning', 'with', 'words', 'allows', 'that', 'of', 'type', 'are', 'human', 'understand', 'computers', 'enables', 'processing', 'natural']\n",
      "\n",
      "Vector for 'language':\n",
      "[ 8.97939038e-03 -3.35828779e-04 -1.89187452e-02 -1.73434038e-02\n",
      " -1.46987271e-02 -1.65980868e-03  6.84558880e-03  2.30456684e-02\n",
      "  8.87850393e-03 -1.16546685e-02  7.84358999e-05  8.34596902e-03\n",
      "  1.90390144e-02 -8.21682450e-04  8.10712297e-03 -7.78956618e-03\n",
      "  3.27510387e-03  2.09856723e-02 -8.32123403e-03 -2.46811584e-02\n",
      "  1.50803132e-02 -4.47599730e-03  1.49425969e-03  2.34314986e-02\n",
      " -1.30913767e-03 -4.84053930e-03 -1.17717581e-02  1.84172690e-02\n",
      " -1.25185186e-02  3.95396352e-03 -1.38499606e-02  1.00322701e-02\n",
      "  1.12605421e-02  2.83364230e-03 -4.33231844e-03 -4.02771495e-03\n",
      "  2.28053648e-02  8.24298523e-03 -6.08202629e-03 -1.95537191e-02\n",
      " -1.02223614e-02 -2.38346611e-03 -2.73163035e-03 -1.87581021e-03\n",
      "  2.20735427e-02 -2.57534464e-03  1.10486001e-02 -1.76740158e-02\n",
      " -5.57762524e-03 -7.96016771e-03]\n",
      "\n",
      "Most similar words to 'word':\n",
      "with: 0.4815\n",
      "step: 0.4679\n",
      "and: 0.4295\n",
      "many: 0.4252\n",
      "is: 0.4169\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "dataset = [\n",
    "    \"Natural language processing enables computers to understand human language\",\n",
    "    \"Word embeddings are a type of word representation that allows words with similar meaning to have similar representation\",\n",
    "    \"Word2Vec is a popular word embedding technique used in many NLP applications\",\n",
    "    \"Text preprocessing is a critical step before training word embeddings\",\n",
    "    \"Tokenization and normalization help clean raw text for modeling\"\n",
    "]\n",
    "\n",
    "tokenized_sentences = [simple_preprocess(doc) for doc in dataset]\n",
    "\n",
    "print(\"Tokenized & preprocessed sentences:\")\n",
    "for sent in tokenized_sentences:\n",
    "    print(sent)\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences=tokenized_sentences,\n",
    "    vector_size=50,\n",
    "    window=3,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    "    sg=1,\n",
    "    epochs=100\n",
    ")\n",
    "\n",
    "print(\"\\nModel vocabulary:\")\n",
    "print(list(model.wv.index_to_key))\n",
    "\n",
    "print(\"\\nVector for 'language':\")\n",
    "print(model.wv[\"language\"])\n",
    "\n",
    "print(\"\\nMost similar words to 'word':\")\n",
    "for word, score in model.wv.most_similar(\"word\", topn=5):\n",
    "    print(f\"{word}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb974c75",
   "metadata": {},
   "source": [
    "**Question 10:** Imagine you are a data scientist at a fintech startup. You’ve been tasked \n",
    "with analyzing customer feedback. Outline the steps you would take to clean, process, \n",
    "and extract useful insights using NLP techniques from thousands of customer reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b441500",
   "metadata": {},
   "source": [
    "### 1. Problem Understanding & Data Collection\n",
    "\n",
    "- Identify the business goals:\n",
    "  - Detect main pain points (e.g., payment failures, KYC issues, app crashes).\n",
    "  - Measure overall customer satisfaction (sentiment).\n",
    "  - Track changes in feedback over time or across product features.\n",
    "- Collect data from:\n",
    "  - App store reviews (Google Play, App Store).\n",
    "  - In-app feedback forms.\n",
    "  - Customer support tickets, emails, chat logs.\n",
    "- Capture useful metadata:\n",
    "  - Review text, rating, timestamp, product/feature, customer ID, platform (Android/iOS).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Data Cleaning\n",
    "\n",
    "- Remove duplicate reviews.\n",
    "- Drop empty or very short reviews (e.g., less than 3–4 words if not useful).\n",
    "- Handle missing values in important fields (text/rating/timestamp).\n",
    "- Fix encoding issues (ensure UTF-8).\n",
    "- Standardize basic formats:\n",
    "  - Timestamps to a single format.\n",
    "  - Consistent language (filter or flag non-English reviews if focusing on English).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Text Preprocessing\n",
    "\n",
    "Apply standard NLP preprocessing steps to the review text:\n",
    "\n",
    "- **Lowercasing**: Convert all text to lowercase.\n",
    "- **Remove noise**:\n",
    "  - Punctuation, extra spaces, special characters.\n",
    "  - URLs, email addresses, user IDs.\n",
    "  - Optional: numbers (unless important, like error codes).\n",
    "- **Tokenization**:\n",
    "  - Split text into tokens (words or subwords).\n",
    "- **Stopword removal**:\n",
    "  - Remove very common words (e.g., “the”, “is”, “and”) that don’t add meaning.\n",
    "- **Lemmatization / Stemming**:\n",
    "  - Convert words to their base forms (e.g., “running” → “run”, “cards” → “card”).\n",
    "- **Handle emojis and slang** (optional but useful):\n",
    "  - Map emojis or common slang to sentiment tags or words if needed.\n",
    "- **Spelling correction** (optional):\n",
    "  - Correct frequent typos in domain-specific terms (e.g., “paytm”, “upi”, brand names).\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Exploratory Analysis (EDA for Text)\n",
    "\n",
    "Use basic statistics to understand the data:\n",
    "\n",
    "- Review length distribution (number of words/chars per review).\n",
    "- Overall rating distribution (1–5 stars).\n",
    "- Word frequency analysis:\n",
    "  - Most common words after preprocessing.\n",
    "  - Most frequent bigrams/trigrams (e.g., “payment failed”, “app crash”, “kyc issue”).\n",
    "- Compare positive vs negative reviews:\n",
    "  - Common words and phrases in each group.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Sentiment Analysis\n",
    "\n",
    "Measure how customers feel:\n",
    "\n",
    "- Label reviews as **positive**, **negative**, or **neutral** using:\n",
    "  - Rule-based models (e.g., VADER) or\n",
    "  - ML models (Logistic Regression, SVM, or deep learning) or\n",
    "  - Pre-trained transformer models (e.g., BERT-based sentiment classifier).\n",
    "- Validate model performance:\n",
    "  - Manually label a sample of reviews.\n",
    "  - Evaluate using accuracy, F1-score, precision, recall.\n",
    "- Aggregate sentiment:\n",
    "  - By time (daily/weekly/monthly).\n",
    "  - By product/feature (UPI, credit card, loans).\n",
    "  - By platform (Android vs iOS).\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Topic Modeling (Discover Main Themes)\n",
    "\n",
    "Find the main topics/issues in the reviews:\n",
    "\n",
    "- Convert reviews to features:\n",
    "  - Bag-of-Words or TF-IDF vectors.\n",
    "  - Or embeddings (Word2Vec, Doc2Vec, sentence transformers).\n",
    "- Apply topic modeling:\n",
    "  - LDA (Latent Dirichlet Allocation).\n",
    "  - NMF (Non-negative Matrix Factorization).\n",
    "  - Or advanced methods like BERTopic (using sentence embeddings).\n",
    "- Interpret and label topics:\n",
    "  - E.g., “Payment Failure”, “KYC Verification Problems”, “Cashback Delays”, “App Performance/Crashes”.\n",
    "- Link topics with sentiment:\n",
    "  - Identify which topics are associated with most negative or most positive sentiment.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Keyword & Phrase Extraction\n",
    "\n",
    "Highlight key phrases customers use:\n",
    "\n",
    "- Use techniques like:\n",
    "  - TF-IDF to get important keywords per segment (e.g., per topic or per product).\n",
    "  - RAKE or YAKE for keyphrase extraction.\n",
    "  - KeyBERT or similar embedding-based methods for more semantic keyphrases.\n",
    "- Extract top keywords for:\n",
    "  - Negative reviews.\n",
    "  - Each topic or product category.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Named Entity Recognition (NER)\n",
    "\n",
    "Identify important entities in the text:\n",
    "\n",
    "- Detect mentions of:\n",
    "  - Brand names, banks, payment gateways.\n",
    "  - Features (UPI, debit card, credit card, loans).\n",
    "  - Locations or countries (if relevant).\n",
    "- Use this to:\n",
    "  - See which partners or features are mentioned often in negative reviews.\n",
    "  - Track complaints tied to a particular bank or payment provider.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Trend & Correlation Analysis\n",
    "\n",
    "Connect text insights with business metrics:\n",
    "\n",
    "- Track **trend over time**:\n",
    "  - How sentiment changes around app releases or new features.\n",
    "  - Spike in certain topics (e.g., “server down”, “login issue”) after a deployment.\n",
    "- Correlate:\n",
    "  - Sentiment with app ratings.\n",
    "  - Certain topics with churn, support tickets, or complaint volume.\n",
    "  - Platform (Android/iOS) with particular error or UX issues.\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Visualization & Reporting\n",
    "\n",
    "Create clear visualizations and dashboards:\n",
    "\n",
    "- Tools: Power BI, Tableau, or custom dashboards (Streamlit, Dash).\n",
    "- Example visuals:\n",
    "  - Sentiment over time.\n",
    "  - Topic distribution (share of each topic).\n",
    "  - Top complaint categories per product or feature.\n",
    "  - Word clouds for positive vs negative reviews.\n",
    "- Summarize findings:\n",
    "  - Use simple tables, charts, and short textual summaries.\n",
    "\n",
    "---\n",
    "\n",
    "### 11. Actionable Insights for the Fintech Startup\n",
    "\n",
    "Translate analysis into concrete actions, for example:\n",
    "\n",
    "- “40% of 1-star reviews mention ‘payment failed’ or ‘transaction pending’.”\n",
    "- “Significant spike in negative sentiment after last app update on [date].”\n",
    "- “KYC verification issues are the most common topic for new users in the last 3 months.”\n",
    "- “Users appreciate cashback offers but are frustrated by payout delays.”\n",
    "\n",
    "Propose actions:\n",
    "\n",
    "- Prioritize bug fixes for high-impact issues (e.g., failed payments).\n",
    "- Improve onboarding and KYC flow.\n",
    "- Refine communication around cashback timelines and eligibility.\n",
    "- Use positive feedback to highlight strengths in marketing (e.g., UX, speed, rewards).\n",
    "\n",
    "---\n",
    "\n",
    "### 12. Automation & Productionization\n",
    "\n",
    "- Build an **end-to-end pipeline**:\n",
    "  - Data ingestion → cleaning → preprocessing → sentiment & topic modeling → dashboards.\n",
    "- Schedule regular updates (daily/weekly).\n",
    "- Monitor model performance and refresh models periodically.\n",
    "- Integrate alerts:\n",
    "  - E.g., notify product team when negative sentiment on a topic spikes.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f109a7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
